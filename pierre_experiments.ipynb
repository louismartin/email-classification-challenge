{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from tools.data_cleansing import clean\n",
    "from tools.data_exploration import print_email_by_id, emails_sent_distribution, emails_received_distribution,\\\n",
    "body_length_distribution, number_of_recipients_distribution\n",
    "from tools.data_handling import enrich_emails, load_email_senders, unique_recipients, address_book, load_emails,\\\n",
    "unique_domain_names, name_to_address, mail_body_orig_message\n",
    "from tools.evaluation import precision\n",
    "from tools.submission import save_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataframe from data/enrich_emails.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>sender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2000-07-25 08:14:00</td>\n",
       "      <td>Legal has been assessing the risks of doing bl...</td>\n",
       "      <td>robert.badeer@enron.com murray.o neil@enron.co...</td>\n",
       "      <td>christian.yoder@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2000-08-03 02:56:00</td>\n",
       "      <td>Attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>kim.ward@enron.com robert.badeer@enron.com mur...</td>\n",
       "      <td>heather.dunton@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2000-08-15 05:37:00</td>\n",
       "      <td>Kevin/Bob: Here is a quick rundown on the cons...</td>\n",
       "      <td>robert.badeer@enron.com john.massey@enron.com ...</td>\n",
       "      <td>janel.guerrero@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2000-08-20 14:12:00</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>robert.badeer@enron.com jeff.richter@enron.com</td>\n",
       "      <td>tim.belden@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2000-08-22 08:17:00</td>\n",
       "      <td>Further to your letter to us (addressed to Mr....</td>\n",
       "      <td>pgillman@schiffhardin.com kamarlantes@calpx.co...</td>\n",
       "      <td>christian.yoder@enron.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date                                               body  \\\n",
       "mid                                                                           \n",
       "60   2000-07-25 08:14:00  Legal has been assessing the risks of doing bl...   \n",
       "66   2000-08-03 02:56:00  Attached is a spreadsheet to estimate export f...   \n",
       "74   2000-08-15 05:37:00  Kevin/Bob: Here is a quick rundown on the cons...   \n",
       "80   2000-08-20 14:12:00  check this out and let everyone know what s up...   \n",
       "83   2000-08-22 08:17:00  Further to your letter to us (addressed to Mr....   \n",
       "\n",
       "                                            recipients  \\\n",
       "mid                                                      \n",
       "60   robert.badeer@enron.com murray.o neil@enron.co...   \n",
       "66   kim.ward@enron.com robert.badeer@enron.com mur...   \n",
       "74   robert.badeer@enron.com john.massey@enron.com ...   \n",
       "80      robert.badeer@enron.com jeff.richter@enron.com   \n",
       "83   pgillman@schiffhardin.com kamarlantes@calpx.co...   \n",
       "\n",
       "                        sender  \n",
       "mid                             \n",
       "60   christian.yoder@enron.com  \n",
       "66    heather.dunton@enron.com  \n",
       "74    janel.guerrero@enron.com  \n",
       "80        tim.belden@enron.com  \n",
       "83   christian.yoder@enron.com  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails = enrich_emails()\n",
    "df_emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: christian.yoder@enron.com\n",
      "To: pgillman@schiffhardin.com kamarlantes@calpx.com robert.badeer@enron.com sewilson@calpx.com\n",
      "On: 2000-08-22 08:17:00\n",
      "Body:\n",
      "    Further to your letter to us (addressed to Mr. Tim Belden)  dated August 14, 2000:  Enron thinks that the elimination of physical risk during the month of August will be of commercial benefit because Enron expects that during the month of August there will be transmission line derations affecting the hour ahead market which will lead to TO debit charges by the CAISO.   The elimination of  TO debit charges is a commercial benefit to Enron.\n"
     ]
    }
   ],
   "source": [
    "print_email_by_id(df_emails, 83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>158713 158697 200301 158679 278595 298162 2002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>215241 3437 215640 3506 191790 3517 3520 3562 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>270705 270706 270707 270708 270709 270710 2707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>111444 111422 183084 111412 111347 110883 1105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>327074 327384 327385 264443 274124 274125 2741...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  158713 158697 200301 158679 278595 298162 2002...  \n",
       "1  215241 3437 215640 3506 191790 3517 3520 3562 ...  \n",
       "2  270705 270706 270707 270708 270709 270710 2707...  \n",
       "3  111444 111422 183084 111412 111347 110883 1105...  \n",
       "4  327074 327384 327385 264443 274124 274125 2741...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_email_senders = load_email_senders(set_type=\"training\")\n",
    "df_email_senders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tokenizing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_rec_train = unique_recipients(df_emails)\n",
    "add_book = address_book(unique_rec_train)\n",
    "add_book.add(\"fyi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "st = LancasterStemmer()\n",
    "def stem(word):\n",
    "    if word in add_book:\n",
    "        return word\n",
    "    else:\n",
    "        return(st.stem(word))\n",
    "def stem_tokenizer(s):\n",
    "    return [stem(word) for word in s.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def split_tokenizer(s):\n",
    "        return s.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_small_senders = df_email_senders.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_emails[df_emails[\"date\"].str.contains(\"0001\")].iterrows():\n",
    "    old_date = df_emails.loc[index, \"date\"]\n",
    "    new_date = \"2\"+old_date[1:]\n",
    "    df_emails.loc[index, \"date\"] = new_date\n",
    "for index, row in df_emails[df_emails[\"date\"].str.contains(\"0002\")].iterrows():\n",
    "    old_date = df_emails.loc[index, \"date\"]\n",
    "    new_date = \"2\"+old_date[1:]\n",
    "    df_emails.loc[index, \"date\"] = new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_emails[\"timestamp\"] = pd.to_datetime(df_emails[\"date\"], format=\"%Y-%m-%d %H:%M:%S\", errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "# import just one row in variable 'row'\n",
    "row = df_email_senders.loc[59]\n",
    "sender = row[\"sender\"]\n",
    "mids = list(map(int, row[\"mids\"].split()))\n",
    "n_mails = len(mids)\n",
    "# data loading and separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099\n",
      "phillip.m.love@enron.com\n"
     ]
    }
   ],
   "source": [
    "print(n_mails)\n",
    "print(sender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_prop = 0.7\n",
    "# data loading and separation\n",
    "df_interest = df_emails.ix[mids]\n",
    "#df_interest.head()\n",
    "df_train = df_interest.sample(frac=train_prop)\n",
    "train_ids = list(df_train.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288750, 288676, 289264, 288949, 288804, 288751, 288864, 289061, 289300, 335948, 288661, 384728, 289277, 288935, 288755, 288660, 289275, 288735, 288846, 289240, 288519, 289102, 289243, 289040, 288625, 288856, 288760, 289002, 288783, 288607, 289204, 288534, 291338, 289254, 288776, 289182, 289321, 288961, 291116, 288785, 291355, 291323, 288689, 288975, 291310, 291246, 289095, 289074, 289033, 288487, 289246, 289131, 288556, 159539, 289076, 288546, 288734, 288584, 288827, 288733, 289235, 291307, 288983, 288744, 289209, 288940, 288490, 288740, 288483, 288637, 289247, 291244, 288987, 288972, 288719, 289256, 288913, 267309, 291311, 289253, 289014, 288798, 289007, 288927, 288784, 291250, 282082, 291316, 292041, 291297, 289067, 288605, 288616, 291367, 288621, 288643, 288721, 288958, 288623, 289198, 288782, 289093, 288844, 291344, 288777, 289217, 288813, 289223, 288882, 288575, 288976, 288552, 288791, 289268, 291277, 291098, 288893, 288480, 288836, 291231, 288528, 288952, 288841, 289126, 288815, 291286, 288959, 289108, 289322, 289210, 288547, 288789, 288979, 291330, 289084, 289153, 291259, 291294, 291301, 289285, 291265, 288832, 288855, 288503, 291337, 291263, 289233, 288635, 288602, 291347, 289024, 288767, 289227, 288475, 288700, 288593, 288583, 288515, 288847, 288878, 291110, 289249, 288971, 288509, 289094, 288965, 289239, 288626, 288724, 288638, 291285, 288654, 289193, 87150, 291255, 291368, 289120, 288872, 288464, 289192, 289295, 288449, 288695, 291228, 289029, 291378, 291260, 288508, 289150, 289107, 288460, 289069, 288453, 289128, 288558, 289160, 288768, 288788, 289185, 289147, 289262, 291374, 288611, 288966, 288780, 288826, 291288, 291239, 291303, 291366, 289213, 291252, 288665, 289115, 289125, 288622, 288933, 291118, 289132, 288647, 289146, 288613, 291258, 291329, 291376, 289188, 158580, 288484, 288569, 289319, 289122, 288931, 288591, 288723, 288634, 289062, 288630, 288698, 289044, 289081, 288860, 288926, 288790, 288631, 289291, 288679, 291105, 291372, 288938, 291109, 291342, 288876, 288896, 288711, 289052, 288499, 288865, 289208, 289287, 288559, 289106, 288482, 288726, 288692, 288915, 289124, 288577, 289112, 289135, 291306, 289263, 288564, 288821, 288538, 288555, 288488, 288574, 288877, 288863, 288524, 288947, 291331, 289036, 291363, 288742, 288739, 288968, 289184, 289034, 335990, 291358, 288939, 291365, 288854, 291240, 288848, 291267, 289064, 288879, 289177, 289045, 288704, 289269, 288530, 289144, 291312, 291346, 288627, 288452, 289252, 288794, 288498, 289049, 289261, 288937, 288570, 289165, 288993, 289085, 289166, 288589, 288986, 289312, 288717, 288973, 289220, 289159, 288478, 288903, 288964, 291123, 291243, 288677, 288597, 291343, 291280, 288617, 288850, 291289, 288451, 291348, 288923, 289276, 288701, 288787, 289266, 288869, 288445, 288873, 289174, 288477, 289030, 289244, 289175, 288467, 291380, 288942, 288567, 289280, 288839, 289051, 288874, 289200, 288511, 289142, 288536, 289039, 288474, 288681, 288901, 288756, 288540, 289307, 291248, 291121, 289059, 288610, 288699, 289274, 289043, 289077, 288694, 289257, 288730, 291100, 291308, 288594, 288994, 289092, 288697, 288800, 282072, 288708, 288828, 288868, 289022, 291264, 288781, 288745, 289026, 288485, 288465, 288563, 291249, 291364, 289323, 288924, 289048, 289041, 289136, 289183, 289140, 288772, 288582, 289027, 289035, 289231, 289057, 288682, 288758, 288580, 288581, 289091, 289055, 291320, 289129, 289157, 288481, 291284, 289281, 291119, 288992, 288853, 289313, 288811, 288572, 288571, 288807, 289103, 288814, 289172, 288796, 288763, 288834, 289212, 291011, 288502, 289195, 289318, 291384, 289292, 291257, 289154, 288512, 288655, 288640, 288495, 288862, 288897, 289053, 288455, 288459, 291262, 291353, 289311, 288518, 288786, 288658, 288516, 161136, 288810, 289028, 291115, 288904, 288586, 291268, 288668, 288666, 289314, 288797, 288825, 288505, 291352, 289293, 291327, 288919, 289250, 289290, 288764, 288554, 288641, 291356, 291318, 288858, 291383, 289096, 289050, 291324, 288606, 289190, 158519, 288718, 288513, 288645, 288738, 288714, 291389, 289248, 291309, 288820, 289105, 289259, 291292, 288943, 288747, 289324, 288936, 288542, 291335, 288819, 291283, 288912, 289152, 288674, 289203, 288531, 288997, 289265, 289068, 289294, 288454, 289178, 291388, 288520, 288544, 288587, 288557, 289310, 288456, 288599, 288716, 288981, 289296, 291350, 288803, 288652, 288823, 288792, 288537, 289098, 288629, 288672, 288898, 288614, 288816, 288859, 288579, 289236, 291296, 291351, 289206, 288491, 288576, 289073, 288533, 291113, 289211, 288941, 289086, 288560, 288928, 288824, 288526, 288945, 289242, 291108, 288757, 288561, 288908, 289270, 291386, 288956, 288922, 288710, 288691, 289284, 291275, 288886, 288619, 288633, 288801, 288793, 289005, 288600, 291295, 289079, 291270, 288496, 288706, 291245, 288944, 289137, 288950, 291293, 288902, 289260, 289225, 291332, 288741, 288504, 289097, 288802, 289123, 289151, 288667, 288553, 289171, 289156, 288914, 288450, 288883, 289161, 289196, 291253, 291354, 288805, 291646, 288727, 291282, 291276, 291099, 288884, 289038, 291272, 291236, 335957, 291234, 288951, 289071, 288916, 291336, 288712, 289004, 289083, 289258, 288492, 288732, 289326, 289031, 291254, 289241, 289205, 288917, 288543, 288970, 291302, 289309, 291102, 291103, 288662, 291251, 289013, 289109, 289010, 289299, 288771, 288769, 288601, 291230, 291326, 288946, 288461, 288675, 288497, 288687, 288507, 288934, 335983, 289023, 291111, 289170, 291241, 288812, 288829, 291266, 289273, 288899, 288649, 288840, 291287, 288851, 289316, 289173, 289162, 291104, 289278, 289090, 291328, 288632, 288759, 289181, 288746, 289020, 288690, 291274, 288510, 288683, 288685, 288954, 289104, 288636, 288671, 289100, 289008, 289191, 288880, 288980, 288985, 289222, 289101, 291359, 291385, 289060, 291114, 288795, 288565, 291357, 289286, 288991, 291261, 288843, 158722, 291269, 288754, 289141, 291107, 288990, 288709, 288562, 289078, 288962, 289164, 288989, 288831, 289283, 289317, 289180, 289302, 288957, 289251, 289046, 288888, 288664, 289149, 288974, 288608, 289308, 288830, 288648, 288736, 288955, 291290, 288894, 291281, 267310, 288657, 288707, 291233, 291273]\n"
     ]
    }
   ],
   "source": [
    "print(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# data cleansing\n",
    "unique_rec_train = unique_recipients(df_train)\n",
    "add_book = address_book(unique_rec_train)\n",
    "df_train[\"clean body\"] = df_train[\"body\"].apply(lambda x : clean(x, except_words=add_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=30,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=15, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "input_bow = TfidfVectorizer(norm=\"l2\",\n",
    "                       tokenizer=stem_tokenizer)\n",
    "X_train = input_bow.fit_transform(df_train[\"clean body\"])\n",
    "hour_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "day_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "output_bow = CountVectorizer(tokenizer=split_tokenizer,\n",
    "                             vocabulary=unique_rec_train)\n",
    "Y_train = output_bow.fit_transform(df_train[\"recipients\"])\n",
    "# model fitting\n",
    "rf = RandomForestRegressor(n_estimators=15,\n",
    "                       max_depth=30,\n",
    "                       n_jobs=-1,\n",
    "                       min_samples_leaf=max(1,int(0.0002*n_mails)))\n",
    "rf.fit(X_train, Y_train.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Zac's idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mazz/Documents/MVA/S2-ALTEGRAD/email-classification-challenge/venv/lib/python3.5/site-packages/ipykernel/__main__.py:36: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "train_prop = 0.7\n",
    "df_small_senders = df_email_senders.sample(frac=0.3)\n",
    "sender_models = dict()\n",
    "sender_input_bow = dict()\n",
    "sender_output_bow = dict()\n",
    "sender_add_book = dict()\n",
    "sender_rec = dict()\n",
    "sender_train_ids = dict()\n",
    "for index, row in df_small_senders.iterrows():\n",
    "    sender = row[\"sender\"]\n",
    "    mids = list(map(int, row[\"mids\"].split()))\n",
    "    n_mails = len(mids)\n",
    "    # data loading and separation\n",
    "    df_interest = df_emails.ix[mids]\n",
    "    df_train = df_interest.sample(frac=train_prop)\n",
    "    train_ids = list(df_train.index.values)\n",
    "    # data cleansing\n",
    "    unique_rec_train = unique_recipients(df_train)\n",
    "    add_book = address_book(unique_rec_train)\n",
    "    df_train[\"clean body\"] = df_train[\"body\"].apply(lambda x : clean(x, except_words=add_book))\n",
    "    # feature engineering\n",
    "    input_bow = TfidfVectorizer(norm=\"l2\",\n",
    "                           tokenizer=stem_tokenizer)\n",
    "    X_train = input_bow.fit_transform(df_train[\"clean body\"])\n",
    "    hour_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "    day_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "    X_train = sparse.hstack((X_train, hour_train, day_train))\n",
    "    output_bow = CountVectorizer(tokenizer=split_tokenizer,\n",
    "                             vocabulary=unique_rec_train)\n",
    "    Y_train = output_bow.fit_transform(df_train[\"recipients\"])\n",
    "    # model fitting\n",
    "    rf = RandomForestRegressor(n_estimators=15,\n",
    "                           max_depth=30,\n",
    "                           n_jobs=-1,\n",
    "                           min_samples_leaf=max(1,int(0.0002*n_mails)))\n",
    "    rf.fit(X_train, Y_train.toarray())\n",
    "    # attributions\n",
    "    sender_models[sender] = rf\n",
    "    sender_rec[sender] = unique_rec_train\n",
    "    sender_add_book[sender] = add_book\n",
    "    sender_input_bow[sender] = input_bow\n",
    "    sender_output_bow[sender] = output_bow\n",
    "    sender_train_ids[sender] = train_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_precision = pd.DataFrame(columns=[\"sender\", \"n_mails\", \"precision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mazz/Documents/MVA/S2-ALTEGRAD/email-classification-challenge/venv/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "top = 10\n",
    "for index, row in df_small_senders.iterrows():\n",
    "    sender = row[\"sender\"]\n",
    "    mids = list(map(int, row[\"mids\"].split()))\n",
    "    # model loading\n",
    "    rf = sender_models[sender]\n",
    "    unique_rec_train = sender_rec[sender]\n",
    "    add_book = sender_add_book[sender]\n",
    "    input_bow = sender_input_bow[sender]\n",
    "    output_bow = sender_output_bow[sender]\n",
    "    train_ids = sender_train_ids[sender]\n",
    "    # data loading\n",
    "    df_interest = df_emails.ix[mids]\n",
    "    train_mask = df_interest.index.isin(train_ids)\n",
    "    df_test = df_interest[~train_mask]\n",
    "    n_mails = df_test.shape[0]\n",
    "    # data cleansing\n",
    "    df_test[\"clean body\"] = df_test[\"body\"].apply(lambda x : clean(x, except_words=add_book))\n",
    "    # feature engineering\n",
    "    X_test = input_bow.transform(df_test[\"clean body\"])\n",
    "    hour_test = sparse.csr_matrix(df_test[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "    day_test = sparse.csr_matrix(df_test[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "    X_test = sparse.hstack((X_test, hour_test, day_test))\n",
    "    # Prediction\n",
    "    Y_test = rf.predict(X_test)\n",
    "    #decoding\n",
    "    recipients_map = output_bow.get_feature_names()\n",
    "    if len(Y_test.shape) > 1 and top < Y_test.shape[1]:\n",
    "        best_pred_idx = np.argpartition(-Y_test, top, axis=1)[:,:top]\n",
    "        sorted_ids = np.argsort(Y_test[np.arange(Y_test.shape[0])[:, None], best_pred_idx])[:,::-1]\n",
    "        sorted_idx = best_pred_idx[np.arange(best_pred_idx.shape[0])[:, None], sorted_ids]\n",
    "    else:\n",
    "        sorted_idx = np.argsort(-Y_test)\n",
    "    preci = 0\n",
    "    for index_test, row_test in df_test.iterrows():\n",
    "        i = df_test.index.get_loc(index_test)\n",
    "        if len(recipients_map) > 1:\n",
    "            rec_ids = sorted_idx[i, :]\n",
    "            rec_pred = \" \".join([recipients_map[rec_id] for rec_id in rec_ids])\n",
    "        else:\n",
    "            rec_pred = recipients_map[0]\n",
    "        preci += precision(rec_pred, row_test[\"recipients\"])\n",
    "    preci /= n_mails\n",
    "    df_precision.loc[index] = [sender, n_mails, preci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X-FileName: john zufferli 6-26-02.PST -----'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.data_cleansing import remove_after_indicator\n",
    "remove_after_indicator(df_test.loc[252208, \"body\"], \"Original Message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x filenam john zufferl pst origin mess rit fred fred rit eal ab ca enron sent tuesday jun amto charlesm epc ca dal mitchel e mail david tesk e mail doug hea e mail frayn donaldson e mail frit de kiewit e mail gary hagerty e mail gary k halabut e mail geoff wagn e mail jim oosterba e mail john maniawsk e mail zufferl john ken wagn e mail doug castellino transcanad com peter karl e mail rick hendrickson e mail rick huery e mail ron raymond e mail tara j konowalec e mail wayn symington e mail kri yadav pancanad ca greg lingelbach transalt com sandy con e mail hly enmax com dan ruiu e mail cc trav shelleysubject gen maint coordin group meet jun wish conf meet pleasenot follow outsid calgary would cal ent cod pound key calgary would cal ent cod poundkey let know quest thank fred rit p eng techn serv esb albert ltd phon cel web sit www eal ab ca http www eal ab ca origin mess rit fred sent friday jun pm charlesm epc ca dal mitchel e mail david tesk e mail doug hea e mail frayn donaldson e mail frit de kiewit e mail gary hagerty e mail gary k halabut e mail geoff wagn e mail jim oosterba e mail johnmaniawsk e mail john zufferl e mail ken wagn e mail doug castellino transcanad com peter karl e mail rick hendrickson e mail rick huery e mail ron raymond e mail tara j konowalec e mail wayn symington e mail kri yadav pancanad ca greg lingelbach transalt com sandyo con e mail hly enmax com dan ruiu e mail cc dug eamon brankovich drag baker rob trav shelley subject gen maintenancecoordin group meet repres yourorg invit attend meet jun pm off tim sint group met inth mean tim put process plac address ongoingsupply adequ concern within albert thank support wewould lik review cur process work examin areasf improv propos follow agend review cur coordin pract inform post pract system control pract coordin inform requir upd maint octob system rest requir issu pleas confirm attend jun un attend perhap would lik telephoneconf meet pleas confirm also pleas adv otheragend item thank fred rit p eng techn serv esb albert ltd phon cel web sit www eal ab ca http www eal ab ca'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.loc[252208, \"clean body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Actual model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mazz/Documents/MVA/S2-ALTEGRAD/email-classification-challenge/venv/lib/python3.5/site-packages/ipykernel/__main__.py:31: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/Mazz/Documents/MVA/S2-ALTEGRAD/email-classification-challenge/venv/lib/python3.5/site-packages/ipykernel/__main__.py:31: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/Mazz/Documents/MVA/S2-ALTEGRAD/email-classification-challenge/venv/lib/python3.5/site-packages/ipykernel/__main__.py:31: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "sender_models = dict()\n",
    "sender_input_bow = dict()\n",
    "sender_output_bow = dict()\n",
    "sender_add_book = dict()\n",
    "sender_rec = dict()\n",
    "for index, row in df_email_senders.iterrows():\n",
    "    sender = row[\"sender\"]\n",
    "    mids = list(map(int, row[\"mids\"].split()))\n",
    "    n_mails = len(mids)\n",
    "    # data loading\n",
    "    df_train = df_emails.ix[mids]\n",
    "    # data cleansing\n",
    "    unique_rec_train = unique_recipients(df_train)\n",
    "    add_book = address_book(unique_rec_train)\n",
    "    df_train[\"clean body\"] = clean(df_train[\"body\"], add_book)\n",
    "    # feature engineering\n",
    "    input_bow = TfidfVectorizer(norm=\"l2\",\n",
    "                           tokenizer=stem_tokenizer)\n",
    "    X_train = input_bow.fit_transform(df_train[\"clean body\"])\n",
    "    hour_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "    day_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "    X_train = sparse.hstack((X_train, hour_train, day_train))\n",
    "    output_bow = CountVectorizer(tokenizer=split_tokenizer,\n",
    "                             vocabulary=unique_rec_train)\n",
    "    Y_train = output_bow.fit_transform(df_train[\"recipients\"])\n",
    "    # model fitting\n",
    "    rf = RandomForestRegressor(n_estimators=15,\n",
    "                           max_depth=30,\n",
    "                           n_jobs=-1,\n",
    "                           min_samples_leaf=max(1,int(0.04*n_mails)))\n",
    "    rf.fit(X_train, Y_train.toarray())\n",
    "    # attributions\n",
    "    sender_models[sender] = rf\n",
    "    sender_rec[sender] = unique_rec_train\n",
    "    sender_add_book[sender] = add_book\n",
    "    sender_input_bow[sender] = input_bow\n",
    "    sender_output_bow[sender] = output_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_submission_senders = load_email_senders(set_type=\"test\")\n",
    "df_submission = load_emails(set_type=\"test\")\n",
    "df_submission[\"recipients\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_submission[df_submission[\"date\"].str.contains(\"0001\")].iterrows():\n",
    "    old_date = df_submission.loc[index, \"date\"]\n",
    "    new_date = \"2\"+old_date[1:]\n",
    "    df_submission.loc[index, \"date\"] = new_date\n",
    "for index, row in df_submission[df_submission[\"date\"].str.contains(\"0002\")].iterrows():\n",
    "    old_date = df_submission.loc[index, \"date\"]\n",
    "    new_date = \"2\"+old_date[1:]\n",
    "    df_submission.loc[index, \"date\"] = new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_submission[\"timestamp\"] = pd.to_datetime(df_submission[\"date\"], format=\"%Y-%m-%d %H:%M:%S\", errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top = 10\n",
    "for index, row in df_submission_senders.iterrows():\n",
    "    sender = row[\"sender\"]\n",
    "    mids = map(int, row[\"mids\"].split())\n",
    "    # data loading\n",
    "    df_eval = df_submission.ix[mids]\n",
    "    # model loading\n",
    "    rf = sender_models[sender]\n",
    "    unique_rec_train = sender_rec[sender]\n",
    "    add_book = sender_add_book[sender]\n",
    "    input_bow = sender_input_bow[sender]\n",
    "    output_bow = sender_output_bow[sender]\n",
    "    # data cleansing\n",
    "    df_eval[\"clean body\"] = clean(df_eval[\"body\"], add_book)\n",
    "    # feature engineering\n",
    "    X_eval = input_bow.transform(df_eval[\"clean body\"])\n",
    "    hour_eval = sparse.csr_matrix(df_eval[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "    day_eval = sparse.csr_matrix(df_eval[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "    X_eval = sparse.hstack((X_eval, hour_eval, day_eval))\n",
    "    # Prediction\n",
    "    Y_eval = rf.predict(X_eval)\n",
    "    #decoding\n",
    "    recipients_map = output_bow.get_feature_names()\n",
    "    if len(Y_eval.shape) > 1 and top < Y_eval.shape[1]:\n",
    "        best_pred_idx = np.argpartition(-Y_eval, top, axis=1)[:,:top]\n",
    "        sorted_ids = np.argsort(Y_eval[np.arange(Y_eval.shape[0])[:, None], best_pred_idx])[:,::-1]\n",
    "        sorted_idx = best_pred_idx[np.arange(best_pred_idx.shape[0])[:, None], sorted_ids]\n",
    "    else:\n",
    "        sorted_idx = np.argsort(-Y_eval)\n",
    "    for index, row in df_eval.iterrows():\n",
    "        i = df_eval.index.get_loc(index)\n",
    "        if len(recipients_map) > 1:\n",
    "            rec_ids = sorted_idx[i, :]\n",
    "            rec_pred = \" \".join([recipients_map[rec_id] for rec_id in rec_ids])\n",
    "        else:\n",
    "            rec_pred = recipients_map[0]\n",
    "        df_submission.set_value(index, \"recipients\", rec_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RF single sender regressor tf idf + date_Pierre_1487205539.555113.csv'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_submission(df_submission,\n",
    "               algo=\"RF single sender regressor tf idf + date\",\n",
    "               member=\"Pierre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
