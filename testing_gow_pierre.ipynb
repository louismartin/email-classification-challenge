{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'bag_of_words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f91a9cc649f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_handling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menrich_emails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_email_senders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_recipients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress_book\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_emails\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_domain_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_to_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmail_body_orig_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_of_emails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmission\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'bag_of_words'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from tools.data_cleansing import clean\n",
    "from tools.data_exploration import print_email_by_id, emails_sent_distribution, emails_received_distribution,\\\n",
    "body_length_distribution, number_of_recipients_distribution\n",
    "from tools.data_handling import enrich_emails, load_email_senders, unique_recipients, address_book, load_emails,\\\n",
    "unique_domain_names, name_to_address, mail_body_orig_message\n",
    "from tools.evaluation import precision\n",
    "from tools.features import bag_of_words, bag_of_emails\n",
    "from tools.submission import save_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data loading and first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_emails = enrich_emails()\n",
    "df_emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_email_by_id(df_emails, 41311)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_email_senders = load_email_senders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "emails_sent_distribution(df_email_senders, max_value=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "emails_received_distribution(df_emails, max_value=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "body_length_distribution(df_emails, max_value=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "number_of_recipients_distribution(df_emails, bins=20, max_value=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_rec = unique_recipients(df_emails)\n",
    "print(\"Number of unique recipients: {}\".format(len(unique_rec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tokenizing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "unique_rec_train = unique_recipients(df_emails)\n",
    "add_book = address_book(unique_rec_train)\n",
    "add_book.add(\"fyi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "st = LancasterStemmer()\n",
    "def stem(word):\n",
    "    if word in add_book:\n",
    "        return word\n",
    "    else:\n",
    "        return(st.stem(word))\n",
    "def stem_tokenizer(s):\n",
    "    return [stem(word) for word in s.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def split_tokenizer(s):\n",
    "        return s.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_small_senders = df_email_senders.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_emails[df_emails[\"date\"].str.contains(\"0001\")].iterrows():\n",
    "    old_date = df_emails.loc[index, \"date\"]\n",
    "    new_date = \"2\"+old_date[1:]\n",
    "    df_emails.loc[index, \"date\"] = new_date\n",
    "for index, row in df_emails[df_emails[\"date\"].str.contains(\"0002\")].iterrows():\n",
    "    old_date = df_emails.loc[index, \"date\"]\n",
    "    new_date = \"2\"+old_date[1:]\n",
    "    df_emails.loc[index, \"date\"] = new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_emails[\"timestamp\"] = pd.to_datetime(df_emails[\"date\"], format=\"%Y-%m-%d %H:%M:%S\", errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "row = df_email_senders.loc[59]\n",
    "sender = row[\"sender\"]\n",
    "mids = list(map(int, row[\"mids\"].split()))\n",
    "n_mails = len(mids)\n",
    "# data loading and separation\n",
    "df_interest = df_emails.ix[mids]\n",
    "df_train = df_interest.sample(frac=train_prop)\n",
    "train_ids = list(df_train.index.values)\n",
    "# data cleansing\n",
    "unique_rec_train = unique_recipients(df_train)\n",
    "add_book = address_book(unique_rec_train)\n",
    "df_train[\"clean body\"] = clean(df_train[\"body\"], add_book)\n",
    "# feature engineering\n",
    "input_bow = TfidfVectorizer(norm=\"l2\",\n",
    "                       tokenizer=stem_tokenizer)\n",
    "X_train = input_bow.fit_transform(df_train[\"clean body\"])\n",
    "hour_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "day_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "Y_train = output_bow.fit_transform(df_train[\"recipients\"])\n",
    "# model fitting\n",
    "rf = RandomForestRegressor(n_estimators=15,\n",
    "                       max_depth=30,\n",
    "                       n_jobs=-1,\n",
    "                       min_samples_leaf=max(1,int(0.0002*n_mails)))\n",
    "rf.fit(X_train, Y_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(hour_train.shape)\n",
    "sparse.hstack((X_train, hour_train, day_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_prop = 0.7\n",
    "sender_models = dict()\n",
    "sender_input_bow = dict()\n",
    "sender_output_bow = dict()\n",
    "sender_add_book = dict()\n",
    "sender_rec = dict()\n",
    "sender_train_ids = dict()\n",
    "for index, row in df_small_senders.iterrows():\n",
    "    sender = row[\"sender\"]\n",
    "    mids = list(map(int, row[\"mids\"].split()))\n",
    "    n_mails = len(mids)\n",
    "    # data loading and separation\n",
    "    df_interest = df_emails.ix[mids]\n",
    "    df_train = df_interest.sample(frac=train_prop)\n",
    "    train_ids = list(df_train.index.values)\n",
    "    # data cleansing\n",
    "    unique_rec_train = unique_recipients(df_train)\n",
    "    add_book = address_book(unique_rec_train)\n",
    "    df_train[\"clean body\"] = clean(df_train[\"body\"], add_book)\n",
    "    # feature engineering\n",
    "    input_bow = TfidfVectorizer(norm=\"l2\",\n",
    "                           tokenizer=stem_tokenizer)\n",
    "    X_train = input_bow.fit_transform(df_train[\"clean body\"])\n",
    "    hour_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "    day_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "    X_train = sparse.hstack((X_train, hour_train, day_train))\n",
    "    output_bow = CountVectorizer(tokenizer=split_tokenizer,\n",
    "                             vocabulary=unique_rec_train)\n",
    "    Y_train = output_bow.fit_transform(df_train[\"recipients\"])\n",
    "    # model fitting\n",
    "    rf = RandomForestRegressor(n_estimators=15,\n",
    "                           max_depth=30,\n",
    "                           n_jobs=-1,\n",
    "                           min_samples_leaf=max(1,int(0.0002*n_mails)))\n",
    "    rf.fit(X_train, Y_train.toarray())\n",
    "    # attributions\n",
    "    sender_models[sender] = rf\n",
    "    sender_rec[sender] = unique_rec_train\n",
    "    sender_add_book[sender] = add_book\n",
    "    sender_input_bow[sender] = input_bow\n",
    "    sender_output_bow[sender] = output_bow\n",
    "    sender_train_ids[sender] = train_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_precision = pd.DataFrame(columns=[\"sender\", \"n_mails\", \"precision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top = 10\n",
    "for index, row in df_small_senders.iterrows():\n",
    "    sender = row[\"sender\"]\n",
    "    mids = list(map(int, row[\"mids\"].split()))\n",
    "    # model loading\n",
    "    rf = sender_models[sender]\n",
    "    unique_rec_train = sender_rec[sender]\n",
    "    add_book = sender_add_book[sender]\n",
    "    input_bow = sender_input_bow[sender]\n",
    "    output_bow = sender_output_bow[sender]\n",
    "    train_ids = sender_train_ids[sender]\n",
    "    # data loading\n",
    "    df_interest = df_emails.ix[mids]\n",
    "    train_mask = df_interest.index.isin(train_ids)\n",
    "    df_test = df_interest[~train_mask]\n",
    "    n_mails = df_test.shape[0]\n",
    "    # data cleansing\n",
    "    df_test[\"clean body\"] = clean(df_test[\"body\"], add_book)\n",
    "    # feature engineering\n",
    "    X_test = input_bow.transform(df_test[\"clean body\"])\n",
    "    hour_test = sparse.csr_matrix(df_test[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "    day_test = sparse.csr_matrix(df_test[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "    X_test = sparse.hstack((X_test, hour_test, day_test))\n",
    "    # Prediction\n",
    "    Y_test = rf.predict(X_test)\n",
    "    #decoding\n",
    "    recipients_map = output_bow.get_feature_names()\n",
    "    if len(Y_test.shape) > 1 and top < Y_test.shape[1]:\n",
    "        best_pred_idx = np.argpartition(-Y_test, top, axis=1)[:,:top]\n",
    "        sorted_ids = np.argsort(Y_test[np.arange(Y_test.shape[0])[:, None], best_pred_idx])[:,::-1]\n",
    "        sorted_idx = best_pred_idx[np.arange(best_pred_idx.shape[0])[:, None], sorted_ids]\n",
    "    else:\n",
    "        sorted_idx = np.argsort(-Y_test)\n",
    "    preci = 0\n",
    "    for index_test, row_test in df_test.iterrows():\n",
    "        i = df_test.index.get_loc(index_test)\n",
    "        if len(recipients_map) > 1:\n",
    "            rec_ids = sorted_idx[i, :]\n",
    "            rec_pred = \" \".join([recipients_map[rec_id] for rec_id in rec_ids])\n",
    "        else:\n",
    "            rec_pred = recipients_map[0]\n",
    "        preci += precision(rec_pred, row_test[\"recipients\"])\n",
    "    preci /= n_mails\n",
    "    df_precision.loc[index] = [sender, n_mails, preci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_precision[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Actual model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sender_models = dict()\n",
    "sender_input_bow = dict()\n",
    "sender_output_bow = dict()\n",
    "sender_add_book = dict()\n",
    "sender_rec = dict()\n",
    "for index, row in df_email_senders.iterrows():\n",
    "    sender = row[\"sender\"]\n",
    "    mids = list(map(int, row[\"mids\"].split()))\n",
    "    n_mails = len(mids)\n",
    "    # data loading\n",
    "    df_train = df_emails.ix[mids]\n",
    "    # data cleansing\n",
    "    unique_rec_train = unique_recipients(df_train)\n",
    "    add_book = address_book(unique_rec_train)\n",
    "    df_train[\"clean body\"] = clean(df_train[\"body\"], add_book)\n",
    "    # feature engineering\n",
    "    input_bow = TfidfVectorizer(norm=\"l2\",\n",
    "                           tokenizer=stem_tokenizer)\n",
    "    X_train = input_bow.fit_transform(df_train[\"clean body\"])\n",
    "    hour_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "    day_train = sparse.csr_matrix(df_train[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "    X_train = sparse.hstack((X_train, hour_train, day_train))\n",
    "    output_bow = CountVectorizer(tokenizer=split_tokenizer,\n",
    "                             vocabulary=unique_rec_train)\n",
    "    Y_train = output_bow.fit_transform(df_train[\"recipients\"])\n",
    "    # model fitting\n",
    "    rf = RandomForestRegressor(n_estimators=15,\n",
    "                           max_depth=30,\n",
    "                           n_jobs=-1,\n",
    "                           min_samples_leaf=max(1,int(0.04*n_mails)))\n",
    "    rf.fit(X_train, Y_train.toarray())\n",
    "    # attributions\n",
    "    sender_models[sender] = rf\n",
    "    sender_rec[sender] = unique_rec_train\n",
    "    sender_add_book[sender] = add_book\n",
    "    sender_input_bow[sender] = input_bow\n",
    "    sender_output_bow[sender] = output_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_submission_senders = load_email_senders(set_type=\"test\")\n",
    "df_submission = load_emails(set_type=\"test\")\n",
    "df_submission[\"recipients\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_submission[df_submission[\"date\"].str.contains(\"0001\")].iterrows():\n",
    "    old_date = df_submission.loc[index, \"date\"]\n",
    "    new_date = \"2\"+old_date[1:]\n",
    "    df_submission.loc[index, \"date\"] = new_date\n",
    "for index, row in df_submission[df_submission[\"date\"].str.contains(\"0002\")].iterrows():\n",
    "    old_date = df_submission.loc[index, \"date\"]\n",
    "    new_date = \"2\"+old_date[1:]\n",
    "    df_submission.loc[index, \"date\"] = new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_submission[\"timestamp\"] = pd.to_datetime(df_submission[\"date\"], format=\"%Y-%m-%d %H:%M:%S\", errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top = 10\n",
    "for index, row in df_submission_senders.iterrows():\n",
    "    sender = row[\"sender\"]\n",
    "    mids = map(int, row[\"mids\"].split())\n",
    "    # data loading\n",
    "    df_eval = df_submission.ix[mids]\n",
    "    # model loading\n",
    "    rf = sender_models[sender]\n",
    "    unique_rec_train = sender_rec[sender]\n",
    "    add_book = sender_add_book[sender]\n",
    "    input_bow = sender_input_bow[sender]\n",
    "    output_bow = sender_output_bow[sender]\n",
    "    # data cleansing\n",
    "    df_eval[\"clean body\"] = clean(df_eval[\"body\"], add_book)\n",
    "    # feature engineering\n",
    "    X_eval = input_bow.transform(df_eval[\"clean body\"])\n",
    "    hour_eval = sparse.csr_matrix(df_eval[\"timestamp\"].dt.hour.as_matrix()).transpose()\n",
    "    day_eval = sparse.csr_matrix(df_eval[\"timestamp\"].dt.dayofweek.as_matrix()).transpose()\n",
    "    X_eval = sparse.hstack((X_eval, hour_eval, day_eval))\n",
    "    # Prediction\n",
    "    Y_eval = rf.predict(X_eval)\n",
    "    #decoding\n",
    "    recipients_map = output_bow.get_feature_names()\n",
    "    if len(Y_eval.shape) > 1 and top < Y_eval.shape[1]:\n",
    "        best_pred_idx = np.argpartition(-Y_eval, top, axis=1)[:,:top]\n",
    "        sorted_ids = np.argsort(Y_eval[np.arange(Y_eval.shape[0])[:, None], best_pred_idx])[:,::-1]\n",
    "        sorted_idx = best_pred_idx[np.arange(best_pred_idx.shape[0])[:, None], sorted_ids]\n",
    "    else:\n",
    "        sorted_idx = np.argsort(-Y_eval)\n",
    "    for index, row in df_eval.iterrows():\n",
    "        i = df_eval.index.get_loc(index)\n",
    "        if len(recipients_map) > 1:\n",
    "            rec_ids = sorted_idx[i, :]\n",
    "            rec_pred = \" \".join([recipients_map[rec_id] for rec_id in rec_ids])\n",
    "        else:\n",
    "            rec_pred = recipients_map[0]\n",
    "        df_submission.set_value(index, \"recipients\", rec_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tools.fine_tuning import expected_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "depths = [2, 5, 10, 15, 20, 30, 50, 100, 300]\n",
    "n = len(depths)\n",
    "p = np.zeros(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i, depth in enumerate(depths):\n",
    "    p[i] = expected_precision(min_sample_prop=0.0002,\n",
    "                             n_estimators=15,\n",
    "                             max_depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "pr = np.zeros(n_trials)\n",
    "for i in range(n_trials):\n",
    "    pr[i] += expected_precision(min_sample_prop=0.04,\n",
    "                             n_estimators=15,\n",
    "                             max_depth=30)\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(depths, p)\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_submission(df_submission,\n",
    "               algo=\"RF single sender regressor tf idf+ date\",\n",
    "               member=\"Zac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
